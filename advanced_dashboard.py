"""
Advanced CAMS Framework Interface
Integrated dashboard combining real data analysis with 13 Universal Laws
Created: July 26, 2025
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import seaborn as sns
import glob
import os
import sys
from typing import Dict, List, Optional

# Add modules to path
sys.path.append('src')
sys.path.append('.')

# Import CAMS components
try:
    from cams_analyzer import CAMSAnalyzer
    from visualizations import CAMSVisualizer
    from advanced_cams_laws import (
        CAMSLaws, CAMSNodeSimulator, create_default_initial_state,
        analyze_real_data_with_laws, plot_network_bonds
    )
except ImportError as e:
    st.error(f"Failed to import CAMS modules: {e}")
    st.stop()

# Page configuration
st.set_page_config(
    page_title="Advanced CAMS Framework",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2c3e50;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
    }
    .law-analysis {
        background-color: #e8f4fd;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .risk-critical {
        background-color: #ffe6e6;
        border-left: 4px solid #dc3545;
    }
    .risk-warning {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
    }
    .risk-stable {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_available_datasets():
    """Load all available CSV datasets with enhanced country name mapping"""
    csv_files = glob.glob("*.csv")
    datasets = {}
    
    # Enhanced country name mapping
    country_mapping = {
        'usa': 'United States',
        'us high res 2025': 'USA (High Resolution)',
        'reconstructed usa dataset': 'USA (Reconstructed)',
        'usa master odd': 'USA (Master)',
        'usa maximum 1790-2025': 'USA (Complete Timeline)',
        'france 1785 1800': 'France (Revolutionary Period)',
        'france master 3': 'France (Extended Period)',
        'new rome ad 5y': 'Roman Empire (Early)',
        'eqmasterrome': 'Roman Empire (Extended)',
        'canada cams 2025': 'Canada (2025)',
        'saudi arabia master file': 'Saudi Arabia',
        'netherlands mastersheet': 'Netherlands',
        'thailand 1850 2025': 'Thailand',
        'japan 1850 2025': 'Japan',
        'germany1750 2025': 'Germany',
        'italy19002025': 'Italy (Modern)',
        'afghanistan ': 'Afghanistan',
        'russia ': 'Russia',
        'israel ': 'Israel',
        'hongkong fixed': 'Hong Kong (Fixed)',
        'hongkong manual': 'Hong Kong (Manual)',
        'hongkong cams cleaned': 'Hong Kong (Cleaned)',
        'denmark cams cleaned (1)': 'Denmark (Alt)',
        'israel - israel': 'Israel (Extended)'
    }
    
    for file in csv_files:
        try:
            df = pd.read_csv(file)
            if len(df) > 0:
                # Clean up country name from filename
                base_name = file.replace('.csv', '').replace('.CSV', '')
                base_name = base_name.replace('_CAMS_Cleaned', '').replace('_', ' ')
                base_name = base_name.strip().lower()
                
                # Use mapping if available, otherwise clean up the name
                if base_name in country_mapping:
                    country_name = country_mapping[base_name]
                else:
                    country_name = base_name.title()
                
                # Try to extract year range from data
                try:
                    # Look for year column
                    year_col = None
                    for col in df.columns:
                        if 'year' in col.lower() or 'date' in col.lower():
                            year_col = col
                            break
                    
                    if year_col and len(df) > 1:
                        year_min = df[year_col].min()
                        year_max = df[year_col].max()
                        years = f"{int(year_min)}-{int(year_max)}"
                    else:
                        years = "Unknown"
                except:
                    years = "Unknown"
                
                # Detect dataset type
                dataset_type = "Traditional"
                if 'Node' in df.columns and 'Coherence' in df.columns:
                    dataset_type = "Node-based"
                
                datasets[country_name] = {
                    'filename': file,
                    'data': df,
                    'records': len(df),
                    'years': years,
                    'columns': len(df.columns),
                    'type': dataset_type,
                    'sample_columns': list(df.columns)[:5]  # First 5 columns for preview
                }
        except Exception as e:
            # Still add problematic files to the list for debugging
            base_name = file.replace('.csv', '').replace('.CSV', '').title()
            datasets[f"{base_name} (Error)"] = {
                'filename': file,
                'data': None,
                'records': 0,
                'years': "Error",
                'columns': 0,
                'type': "Error",
                'error': str(e),
                'sample_columns': []
            }
            continue
    
    return datasets

@st.cache_data
def analyze_dataset_with_laws(df: pd.DataFrame, country_name: str):
    """Analyze dataset using both traditional CAMS and 13 Laws"""
    try:
        # Traditional CAMS analysis
        analyzer = CAMSAnalyzer()
        
        # Get basic metrics
        year_col = analyzer._get_column_name(df, 'year')
        latest_year = df[year_col].max()
        
        system_health = analyzer.calculate_system_health(df, latest_year)
        summary_report = analyzer.generate_summary_report(df, country_name)
        
        # Advanced Laws analysis
        laws_analysis = analyze_real_data_with_laws(df, country_name)
        
        return {
            'basic_analysis': {
                'system_health': system_health,
                'summary_report': summary_report
            },
            'laws_analysis': laws_analysis,
            'latest_year': latest_year,
            'success': True
        }
        
    except Exception as e:
        return {
            'error': str(e),
            'success': False
        }

def display_civilization_overview(country_data: Dict, analysis_results: Dict):
    """Display comprehensive civilization overview"""
    st.markdown('<div class="main-header">üåç Advanced Civilization Analysis</div>', unsafe_allow_html=True)
    
    # Basic information
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Dataset", country_data['filename'])
    with col2:
        st.metric("Records", f"{country_data['records']:,}")
    with col3:
        st.metric("Time Span", country_data['years'])
    with col4:
        if analysis_results['success']:
            st.metric("Latest Year", analysis_results['latest_year'])
    
    if not analysis_results['success']:
        st.error(f"Analysis failed: {analysis_results['error']}")
        return
    
    # Core metrics
    st.markdown('<div class="sub-header">üìä Core CAMS Metrics</div>', unsafe_allow_html=True)
    
    basic = analysis_results['basic_analysis']
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        health = basic['system_health']
        health_color = "normal"
        if health < 50:
            health_color = "inverse"
        st.metric("System Health", f"{health:.2f}", help="Overall civilizational health index")
    
    with col2:
        civ_type = basic['summary_report'].get('civilization_type', 'Unknown')
        st.metric("Civilization Type", civ_type)
    
    with col3:
        trajectory = basic['summary_report'].get('health_trajectory', 'Unknown')
        st.metric("Trajectory", trajectory)
    
    with col4:
        transitions = len(basic['summary_report'].get('phase_transitions', []))
        st.metric("Phase Transitions", transitions)

def display_thirteen_laws_analysis(laws_analysis: Dict):
    """Display comprehensive 13 Laws analysis"""
    st.markdown('<div class="sub-header">‚öñÔ∏è Universal Laws Analysis</div>', unsafe_allow_html=True)
    
    laws = laws_analysis['laws_analysis']
    
    # Create tabs for different law categories
    tab1, tab2, tab3, tab4 = st.tabs(["üéØ Core Laws", "üîó Network Laws", "‚ö° Dynamics Laws", "üîÆ Prediction Laws"])
    
    with tab1:
        st.markdown("**Law 1: Capacity-Stress Balance**")
        capacity_stress = laws['law_1_capacity_stress']
        col1, col2 = st.columns(2)
        with col1:
            st.metric("System Balance", f"{capacity_stress['system_balance']:.2f}")
        with col2:
            imbalanced = len(capacity_stress['imbalanced_nodes'])
            st.metric("Imbalanced Nodes", imbalanced)
        
        if capacity_stress['imbalanced_nodes']:
            st.warning(f"Imbalanced nodes: {', '.join(capacity_stress['imbalanced_nodes'])}")
        
        st.markdown("**Law 6: System Fitness**")
        fitness = laws['law_6_system_fitness']
        col1, col2 = st.columns(2)
        with col1:
            st.metric("System Fitness", f"{fitness['system_fitness']:.2f}")
        with col2:
            low_fitness = len(fitness['low_fitness_nodes'])
            st.metric("Low Fitness Nodes", low_fitness)
    
    with tab2:
        st.markdown("**Law 8: Bond Strength Matrix**")
        bonds = laws['law_8_bond_strength']
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Avg Bond Strength", f"{bonds['average_bond_strength']:.3f}")
        with col2:
            st.metric("Network Density", f"{bonds['network_density']:.3f}")
        with col3:
            st.metric("Most Connected", bonds['most_connected_node'])
        
        st.markdown("**Law 9: Synchronization**")
        sync = laws['law_9_synchronization']
        col1, col2 = st.columns(2)
        with col1:
            st.metric("System Sync Level", f"{sync['system_sync_level']:.3f}")
        with col2:
            synchronized = len(sync['synchronized_nodes'])
            st.metric("Synchronized Nodes", synchronized)
    
    with tab3:
        st.markdown("**Law 7: Elite Circulation**")
        elite = laws['law_7_elite_circulation']
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Elite Vitality", f"{elite['average_elite_vitality']:.2f}")
        with col2:
            circulation_needed = "Yes" if elite['circulation_needed'] else "No"
            st.metric("Circulation Needed", circulation_needed)
        
        if elite['stagnant_elites']:
            st.warning(f"Stagnant elites: {', '.join(elite['stagnant_elites'])}")
        
        st.markdown("**Law 11: Stress Cascade**")
        cascade = laws['law_11_stress_cascade']
        vulnerable = cascade['cascade_vulnerable_nodes']
        
        if vulnerable:
            st.error(f"Cascade vulnerable nodes: {', '.join(vulnerable)}")
        else:
            st.success("No cascade vulnerabilities detected")
    
    with tab4:
        st.markdown("**Law 12: Metastability Detection**")
        meta = laws['law_12_metastability']
        
        col1, col2 = st.columns(2)
        with col1:
            metastable = "Yes" if meta['system_metastable'] else "No"
            st.metric("System Metastable", metastable)
        with col2:
            st.metric("Metastability Risk", f"{meta['metastability_risk']:.3f}")
        
        st.markdown("**Law 13: Transformation Potential**")
        transform = laws['law_13_transformation']
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Transform Score", f"{transform['transformation_score']:.3f}")
        with col2:
            likely = "Yes" if transform['transformation_likely'] else "No"
            st.metric("Likely", likely)
        with col3:
            st.metric("Type", transform['transformation_type'])

def display_risk_assessment(analysis_results: Dict):
    """Display comprehensive risk assessment"""
    st.markdown('<div class="sub-header">‚ö†Ô∏è Risk Assessment Matrix</div>', unsafe_allow_html=True)
    
    if not analysis_results['success']:
        st.error("Cannot perform risk assessment - analysis failed")
        return
    
    basic = analysis_results['basic_analysis']
    laws = analysis_results['laws_analysis']['laws_analysis']
    
    # Calculate risk factors
    health_risk = basic['system_health'] < 50
    fitness_risk = laws['law_6_system_fitness']['system_fitness'] < 15
    cascade_risk = len(laws['law_11_stress_cascade']['cascade_vulnerable_nodes']) > 0
    elite_risk = laws['law_7_elite_circulation']['circulation_needed']
    metastability_risk = laws['law_12_metastability']['system_metastable']
    
    risk_factors = [
        ("System Health Critical", health_risk, "Health below stability threshold"),
        ("Low System Fitness", fitness_risk, "Overall system effectiveness compromised"),
        ("Stress Cascade Risk", cascade_risk, "Vulnerable to cascade failures"),
        ("Elite Stagnation", elite_risk, "Leadership circulation needed"),
        ("Metastability Present", metastability_risk, "System in unstable equilibrium")
    ]
    
    # Count total risks
    total_risks = sum(risk for _, risk, _ in risk_factors)
    
    # Overall risk level
    if total_risks >= 4:
        risk_level = "CRITICAL"
        risk_class = "risk-critical"
        risk_color = "#dc3545"
    elif total_risks >= 2:
        risk_level = "ELEVATED"
        risk_class = "risk-warning"  
        risk_color = "#ffc107"
    else:
        risk_level = "STABLE"
        risk_class = "risk-stable"
        risk_color = "#28a745"
    
    # Display overall risk
    st.markdown(f"""
    <div class="metric-card {risk_class}">
        <h3>Overall Risk Level: {risk_level}</h3>
        <p>Risk Factors Active: {total_risks}/5</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Display individual risk factors
    col1, col2 = st.columns(2)
    
    for i, (factor, is_risk, description) in enumerate(risk_factors):
        target_col = col1 if i % 2 == 0 else col2
        
        with target_col:
            if is_risk:
                st.error(f"üî¥ {factor}: {description}")
            else:
                st.success(f"üü¢ {factor}: Normal")

def display_comparative_analysis(datasets: Dict):
    """Display comparative analysis across multiple civilizations"""
    st.markdown('<div class="sub-header">üîÑ Comparative Civilization Analysis</div>', unsafe_allow_html=True)
    
    if len(datasets) < 2:
        st.warning("Select multiple datasets for comparative analysis")
        return
    
    # Allow user to select datasets for comparison
    selected_for_comparison = st.multiselect(
        "Select civilizations to compare:",
        options=list(datasets.keys()),
        default=list(datasets.keys())[:5]  # First 5 by default
    )
    
    if len(selected_for_comparison) < 2:
        st.warning("Please select at least 2 civilizations for comparison")
        return
    
    # Analyze selected datasets
    comparison_data = []
    
    with st.spinner("Analyzing selected civilizations..."):
        for country in selected_for_comparison:
            try:
                df = datasets[country]['data']
                analysis = analyze_dataset_with_laws(df, country)
                
                if analysis['success']:
                    laws = analysis['laws_analysis']['laws_analysis']
                    basic = analysis['basic_analysis']
                    
                    comparison_data.append({
                        'Civilization': country,
                        'System Health': basic['system_health'],
                        'System Fitness': laws['law_6_system_fitness']['system_fitness'],
                        'Transform Score': laws['law_13_transformation']['transformation_score'],
                        'Elite Vitality': laws['law_7_elite_circulation']['average_elite_vitality'],
                        'Network Density': laws['law_8_bond_strength']['network_density'],
                        'Records': datasets[country]['records']
                    })
            except Exception as e:
                st.warning(f"Failed to analyze {country}: {e}")
    
    if not comparison_data:
        st.error("No datasets could be analyzed for comparison")
        return
    
    # Create comparison DataFrame
    comp_df = pd.DataFrame(comparison_data)
    
    # Display comparison table
    st.markdown("**Comparative Metrics Table**")
    st.dataframe(comp_df.round(3), use_container_width=True)
    
    # Create comparative visualizations
    col1, col2 = st.columns(2)
    
    with col1:
        # System Health comparison
        fig_health = px.bar(
            comp_df, 
            x='Civilization', 
            y='System Health',
            title='System Health Comparison',
            color='System Health',
            color_continuous_scale='RdYlGn'
        )
        fig_health.update_layout(height=400)
        st.plotly_chart(fig_health, use_container_width=True)
    
    with col2:
        # System Fitness vs Transform Score
        fig_scatter = px.scatter(
            comp_df,
            x='System Fitness',
            y='Transform Score', 
            size='Records',
            hover_name='Civilization',
            title='Fitness vs Transformation Potential',
            color='Elite Vitality',
            color_continuous_scale='viridis'
        )
        fig_scatter.update_layout(height=400)
        st.plotly_chart(fig_scatter, use_container_width=True)

def create_theoretical_simulation_interface():
    """Create interface for theoretical CAMS simulation"""
    st.markdown('<div class="sub-header">üß™ Theoretical Simulation Laboratory</div>', unsafe_allow_html=True)
    
    with st.expander("Run Theoretical CAMS Simulation"):
        st.markdown("**Configure Initial Civilization State**")
        
        # Basic parameters
        col1, col2 = st.columns(2)
        with col1:
            time_span = st.slider("Simulation Years", 10, 100, 50)
            coupling_strength = st.slider("Network Coupling", 0.01, 0.5, 0.1)
        
        with col2:
            add_shocks = st.checkbox("Add External Shocks")
            show_laws = st.checkbox("Show Laws Compliance", value=True)
        
        if st.button("Run Simulation"):
            with st.spinner("Running theoretical simulation..."):
                try:
                    # Create initial state
                    initial_nodes = create_default_initial_state()
                    
                    # Add shocks if requested
                    shock_timeline = None
                    if add_shocks:
                        shock_timeline = {
                            time_span * 0.3: {  # Economic crisis at 30%
                                'Executive': [0.0, 0.0, 2.0, 0.5],
                                'Property_Owners': [-1.0, -0.5, 1.5, 0.0],
                            },
                            time_span * 0.7: {  # Social unrest at 70%
                                'Proletariat': [-0.5, -0.8, 2.5, 0.0],
                                'Army': [0.5, 1.0, 0.5, 0.0],
                            }
                        }
                    
                    # Run simulation
                    simulator = CAMSNodeSimulator(initial_nodes, coupling_strength)
                    times, trajectories = simulator.simulate(
                        time_span=(0, time_span),
                        dt=0.2,
                        external_shocks_timeline=shock_timeline
                    )
                    
                    # Display results
                    st.success("Simulation completed!")
                    
                    # Create visualization
                    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
                    variables = ['Coherence', 'Capacity', 'Stress', 'Abstraction']
                    colors = plt.cm.tab10(np.linspace(0, 1, 8))
                    
                    for var_idx, (ax, var_name) in enumerate(zip(axes.flat, variables)):
                        for node_idx, color in enumerate(colors):
                            ax.plot(times, trajectories[:, node_idx, var_idx], 
                                   color=color, alpha=0.8, linewidth=1.5)
                        
                        ax.set_title(f'{var_name} Evolution')
                        ax.set_xlabel('Time')
                        ax.set_ylabel(var_name)
                        ax.grid(True, alpha=0.3)
                    
                    plt.suptitle('Theoretical CAMS Evolution', fontsize=14)
                    plt.tight_layout()
                    st.pyplot(fig)
                    
                    # Final state analysis
                    if show_laws:
                        final_nodes = trajectories[-1]
                        initial_nodes_for_comparison = trajectories[0]
                        
                        simulator_analysis = simulator.analyze_laws_compliance(
                            final_nodes, initial_nodes_for_comparison
                        )
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            fitness = simulator_analysis['law_6_system_fitness']['system_fitness']
                            st.metric("Final Fitness", f"{fitness:.2f}")
                        with col2:
                            transform = simulator_analysis['law_13_transformation']['transformation_score']
                            st.metric("Transform Score", f"{transform:.3f}")
                        with col3:
                            circulation = simulator_analysis['law_7_elite_circulation']['circulation_needed']
                            st.metric("Elite Circulation", "Needed" if circulation else "Stable")
                
                except Exception as e:
                    st.error(f"Simulation failed: {e}")

def create_advanced_analytics_suite(datasets: Dict, selected_country: str):
    """Advanced analytics suite with specialized tools"""
    st.markdown('<div class="sub-header">üî¨ Advanced Analytics Suite</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üìà Time Series Analysis**")
        if st.button("Run Trend Analysis"):
            if selected_country and selected_country in datasets:
                df = datasets[selected_country]['data']
                
                try:
                    from cams_analyzer import CAMSAnalyzer
                    analyzer = CAMSAnalyzer()
                    
                    year_col = analyzer._get_column_name(df, 'year')
                    years = sorted(df[year_col].unique())
                    
                    health_timeline = []
                    for year in years:
                        health = analyzer.calculate_system_health(df, year)
                        health_timeline.append((year, health))
                    
                    # Create trend chart
                    import plotly.graph_objects as go
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=[h[0] for h in health_timeline],
                        y=[h[1] for h in health_timeline],
                        mode='lines+markers',
                        name='System Health'
                    ))
                    fig.update_layout(title=f'{selected_country} - Health Trend Analysis')
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Trend statistics
                    st.metric("Health Trend", f"{'Improving' if health_timeline[-1][1] > health_timeline[0][1] else 'Declining'}")
                    
                except Exception as e:
                    st.error(f"Trend analysis failed: {e}")
        
        st.markdown("**üé≤ Monte Carlo Simulation**")
        if st.button("Run Monte Carlo Analysis"):
            st.info("Running 1000 simulations with random perturbations...")
            try:
                from advanced_cams_laws import CAMSNodeSimulator, create_default_initial_state
                import numpy as np
                
                # Run multiple simulations
                results = []
                for i in range(100):  # Reduced for speed
                    initial_state = create_default_initial_state()
                    # Add random perturbation
                    noise = np.random.normal(0, 0.5, initial_state.shape)
                    perturbed_state = initial_state + noise
                    
                    simulator = CAMSNodeSimulator(perturbed_state)
                    times, trajectories = simulator.simulate(time_span=(0, 20), dt=1)
                    
                    final_analysis = simulator.analyze_laws_compliance(trajectories[-1])
                    fitness = final_analysis['law_6_system_fitness']['system_fitness']
                    results.append(fitness)
                
                # Display results
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric("Mean Fitness", f"{np.mean(results):.2f}")
                with col_b:
                    st.metric("Std Dev", f"{np.std(results):.2f}")
                with col_c:
                    st.metric("Success Rate", f"{sum(1 for r in results if r > 10)/len(results)*100:.1f}%")
                    
            except Exception as e:
                st.error(f"Monte Carlo analysis failed: {e}")
    
    with col2:
        st.markdown("**üß† Pattern Recognition**")
        if st.button("Detect Patterns"):
            st.info("Analyzing patterns across all datasets...")
            
            try:
                patterns = []
                for country, data in datasets.items():
                    df = data['data']
                    analysis = analyze_dataset_with_laws(df, country)
                    
                    if analysis['success']:
                        laws = analysis['laws_analysis']
                        patterns.append({
                            'Country': country,
                            'Fitness': laws['law_6_system_fitness']['system_fitness'],
                            'Transform': laws['law_13_transformation']['transformation_score'],
                            'Elite_Vitality': laws['law_7_elite_circulation']['average_elite_vitality']
                        })
                
                if patterns:
                    import pandas as pd
                    pattern_df = pd.DataFrame(patterns)
                    
                    # Correlation analysis
                    st.markdown("**Pattern Correlations:**")
                    corr_matrix = pattern_df[['Fitness', 'Transform', 'Elite_Vitality']].corr()
                    st.dataframe(corr_matrix)
                    
                    # Clustering
                    from sklearn.cluster import KMeans
                    if len(pattern_df) >= 3:
                        kmeans = KMeans(n_clusters=3, random_state=42)
                        clusters = kmeans.fit_predict(pattern_df[['Fitness', 'Elite_Vitality']])
                        pattern_df['Cluster'] = clusters
                        
                        st.markdown("**Civilization Clusters:**")
                        for cluster in range(3):
                            cluster_countries = pattern_df[pattern_df['Cluster'] == cluster]['Country'].tolist()
                            st.write(f"Cluster {cluster + 1}: {', '.join(cluster_countries)}")
                    
            except Exception as e:
                st.error(f"Pattern recognition failed: {e}")
        
        st.markdown("**üîç Anomaly Detection**")
        if st.button("Detect Anomalies"):
            st.info("Scanning for statistical anomalies...")
            
            try:
                anomalies = []
                for country, data in datasets.items():
                    df = data['data']
                    analysis = analyze_dataset_with_laws(df, country)
                    
                    if analysis['success']:
                        laws = analysis['laws_analysis']
                        fitness = laws['law_6_system_fitness']['system_fitness']
                        
                        # Check for anomalous conditions
                        if fitness < 1.0:
                            anomalies.append(f"‚ö†Ô∏è {country}: Critical fitness ({fitness:.2f})")
                        
                        cascade_nodes = laws['law_11_stress_cascade']['cascade_vulnerable_nodes']
                        if len(cascade_nodes) > 4:
                            anomalies.append(f"üî¥ {country}: High cascade risk ({len(cascade_nodes)} nodes)")
                
                if anomalies:
                    st.markdown("**Detected Anomalies:**")
                    for anomaly in anomalies:
                        st.write(anomaly)
                else:
                    st.success("No critical anomalies detected")
                    
            except Exception as e:
                st.error(f"Anomaly detection failed: {e}")

def create_data_export_interface(datasets: Dict, selected_country: str):
    """Data export and reporting interface"""
    st.markdown('<div class="sub-header">üìä Data Export & Reports</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**üìÑ Generate Reports**")
        
        report_type = st.selectbox(
            "Report Type:",
            ["Comprehensive Analysis", "Risk Assessment", "Laws Compliance", "Comparative Study"]
        )
        
        if st.button("Generate Report"):
            if selected_country and selected_country in datasets:
                df = datasets[selected_country]['data']
                analysis = analyze_dataset_with_laws(df, selected_country)
                
                if analysis['success']:
                    report_content = f"""
# CAMS Analysis Report: {selected_country}
Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

## Executive Summary
- **Dataset**: {datasets[selected_country]['filename']}
- **Records**: {datasets[selected_country]['records']:,}
- **Time Span**: {datasets[selected_country]['years']}
- **Analysis Year**: {analysis['latest_year']}

## System Metrics
"""
                    laws = analysis['laws_analysis']
                    
                    if report_type == "Comprehensive Analysis":
                        report_content += f"""
### Universal Laws Analysis
- **System Fitness**: {laws['law_6_system_fitness']['system_fitness']:.2f}
- **Elite Vitality**: {laws['law_7_elite_circulation']['average_elite_vitality']:.2f}
- **Transformation Score**: {laws['law_13_transformation']['transformation_score']:.3f}
- **Network Density**: {laws['law_8_bond_strength']['network_density']:.3f}

### Risk Factors
- **Metastable**: {laws['law_12_metastability']['system_metastable']}
- **Cascade Vulnerable Nodes**: {len(laws['law_11_stress_cascade']['cascade_vulnerable_nodes'])}
- **Stagnant Elites**: {len(laws['law_7_elite_circulation']['stagnant_elites'])}
"""
                    
                    st.text_area("Generated Report", report_content, height=300)
                    
                    # Download button
                    st.download_button(
                        label="Download Report",
                        data=report_content,
                        file_name=f"{selected_country}_CAMS_Report.md",
                        mime="text/markdown"
                    )
    
    with col2:
        st.markdown("**üíæ Export Data**")
        
        export_format = st.selectbox(
            "Export Format:",
            ["CSV", "JSON", "Excel"]
        )
        
        if st.button("Export Analysis Data"):
            if selected_country and selected_country in datasets:
                df = datasets[selected_country]['data']
                analysis = analyze_dataset_with_laws(df, selected_country)
                
                if analysis['success']:
                    if export_format == "CSV":
                        csv_data = df.to_csv(index=False)
                        st.download_button(
                            label="Download CSV",
                            data=csv_data,
                            file_name=f"{selected_country}_analysis.csv",
                            mime="text/csv"
                        )
                    elif export_format == "JSON":
                        json_data = analysis
                        import json
                        json_str = json.dumps(json_data, indent=2, default=str)
                        st.download_button(
                            label="Download JSON",
                            data=json_str,
                            file_name=f"{selected_country}_analysis.json",
                            mime="application/json"
                        )

def create_custom_law_testing_interface(datasets: Dict, selected_country: str):
    """Custom law testing interface"""
    st.markdown('<div class="sub-header">üéØ Custom Law Testing</div>', unsafe_allow_html=True)
    
    st.markdown("**Create Custom CAMS Law**")
    
    law_name = st.text_input("Law Name", "My Custom Law")
    law_description = st.text_area("Law Description", "Describe your custom law...")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Input Variables**")
        use_coherence = st.checkbox("Coherence", value=True)
        use_capacity = st.checkbox("Capacity", value=True)
        use_stress = st.checkbox("Stress", value=False)
        use_abstraction = st.checkbox("Abstraction", value=False)
        
    with col2:
        st.markdown("**Formula Builder**")
        operation = st.selectbox("Operation", ["Addition", "Multiplication", "Ratio", "Custom"])
        threshold = st.number_input("Threshold Value", value=10.0)
    
    if st.button("Test Custom Law"):
        if selected_country and selected_country in datasets:
            st.info(f"Testing '{law_name}' on {selected_country}...")
            
            try:
                df = datasets[selected_country]['data']
                analysis = analyze_dataset_with_laws(df, selected_country)
                
                if analysis['success']:
                    nodes = analysis['raw_nodes']
                    
                    # Apply custom law
                    result_values = []
                    for i in range(len(nodes)):
                        value = 0
                        if use_coherence:
                            value += nodes[i][0]
                        if use_capacity:
                            value += nodes[i][1]
                        if use_stress:
                            value -= nodes[i][2]  # Subtract stress
                        if use_abstraction:
                            value -= nodes[i][3] * 0.5  # Penalize abstraction
                        
                        result_values.append(value)
                    
                    # Display results
                    avg_result = np.mean(result_values)
                    st.metric("Custom Law Result", f"{avg_result:.2f}")
                    
                    if avg_result > threshold:
                        st.success(f"Law condition MET (>{threshold})")
                    else:
                        st.warning(f"Law condition NOT MET (<{threshold})")
                    
                    # Visualization
                    import plotly.graph_objects as go
                    fig = go.Figure(data=go.Bar(
                        x=CAMSNodeSimulator.NODE_NAMES,
                        y=result_values,
                        name=law_name
                    ))
                    fig.update_layout(title=f"Custom Law: {law_name}")
                    st.plotly_chart(fig, use_container_width=True)
                    
            except Exception as e:
                st.error(f"Custom law testing failed: {e}")

def create_network_analysis_interface(datasets: Dict, selected_country: str):
    """Network analysis tools"""
    st.markdown('<div class="sub-header">üåê Network Analysis Tools</div>', unsafe_allow_html=True)
    
    if selected_country and selected_country in datasets:
        df = datasets[selected_country]['data']
        analysis = analyze_dataset_with_laws(df, selected_country)
        
        if analysis['success']:
            laws = analysis['laws_analysis']
            bond_data = laws['law_8_bond_strength']
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**Network Metrics**")
                st.metric("Average Bond Strength", f"{bond_data['average_bond_strength']:.3f}")
                st.metric("Network Density", f"{bond_data['network_density']:.3f}")
                st.metric("Most Connected Node", bond_data['most_connected_node'])
                
                st.markdown("**Centrality Analysis**")
                if st.button("Calculate Centrality"):
                    try:
                        from advanced_cams_laws import CAMSLaws
                        laws_obj = CAMSLaws(analysis['raw_nodes'], CAMSNodeSimulator.NODE_NAMES)
                        bond_matrix, _ = laws_obj.law_8_bond_strength_matrix()
                        
                        # Calculate centrality measures
                        centrality_scores = np.sum(bond_matrix, axis=1)
                        centrality_data = list(zip(CAMSNodeSimulator.NODE_NAMES, centrality_scores))
                        centrality_data.sort(key=lambda x: x[1], reverse=True)
                        
                        st.markdown("**Node Centrality Ranking:**")
                        for i, (node, score) in enumerate(centrality_data[:5]):
                            st.write(f"{i+1}. {node}: {score:.3f}")
                            
                    except Exception as e:
                        st.error(f"Centrality calculation failed: {e}")
            
            with col2:
                st.markdown("**Network Visualization**")
                if st.button("Generate Network Graph"):
                    try:
                        import networkx as nx
                        import plotly.graph_objects as go
                        
                        from advanced_cams_laws import CAMSLaws
                        laws_obj = CAMSLaws(analysis['raw_nodes'], CAMSNodeSimulator.NODE_NAMES)
                        bond_matrix, _ = laws_obj.law_8_bond_strength_matrix()
                        
                        # Create network graph
                        G = nx.Graph()
                        node_names = CAMSNodeSimulator.NODE_NAMES
                        
                        for i in range(len(node_names)):
                            G.add_node(i, name=node_names[i])
                        
                        for i in range(len(bond_matrix)):
                            for j in range(i+1, len(bond_matrix)):
                                if bond_matrix[i][j] > 0.3:  # Only strong bonds
                                    G.add_edge(i, j, weight=bond_matrix[i][j])
                        
                        # Layout
                        pos = nx.spring_layout(G)
                        
                        # Create edges
                        edge_x = []
                        edge_y = []
                        for edge in G.edges():
                            x0, y0 = pos[edge[0]]
                            x1, y1 = pos[edge[1]]
                            edge_x.extend([x0, x1, None])
                            edge_y.extend([y0, y1, None])
                        
                        edge_trace = go.Scatter(x=edge_x, y=edge_y,
                                             line=dict(width=0.5, color='#888'),
                                             hoverinfo='none',
                                             mode='lines')
                        
                        # Create nodes
                        node_x = []
                        node_y = []
                        node_text = []
                        for node in G.nodes():
                            x, y = pos[node]
                            node_x.append(x)
                            node_y.append(y)
                            node_text.append(node_names[node])
                        
                        node_trace = go.Scatter(x=node_x, y=node_y,
                                              mode='markers+text',
                                              text=node_text,
                                              textposition="middle center",
                                              hoverinfo='text',
                                              marker=dict(size=20,
                                                        color='lightblue',
                                                        line=dict(width=2, color='black')))
                        
                        fig = go.Figure(data=[edge_trace, node_trace],
                                       layout=go.Layout(
                                            title=f'{selected_country} - Node Network',
                                            showlegend=False,
                                            hovermode='closest',
                                            margin=dict(b=20,l=5,r=5,t=40),
                                            annotations=[ dict(
                                                text="Network connections based on bond strengths",
                                                showarrow=False,
                                                xref="paper", yref="paper",
                                                x=0.005, y=-0.002 ) ],
                                            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                    except Exception as e:
                        st.error(f"Network visualization failed: {e}")

def create_realtime_monitoring_interface(datasets: Dict):
    """Real-time monitoring interface"""
    st.markdown('<div class="sub-header">‚ö° Real-time Monitoring</div>', unsafe_allow_html=True)
    
    st.markdown("**System Health Dashboard**")
    
    # Auto-refresh option
    auto_refresh = st.checkbox("Auto-refresh every 30 seconds")
    
    if auto_refresh:
        st.rerun()
    
    # Monitor multiple datasets
    monitoring_datasets = st.multiselect(
        "Select datasets to monitor:",
        options=list(datasets.keys()),
        default=list(datasets.keys())[:5]
    )
    
    if monitoring_datasets:
        health_data = []
        risk_alerts = []
        
        for country in monitoring_datasets:
            try:
                df = datasets[country]['data']
                analysis = analyze_dataset_with_laws(df, country)
                
                if analysis['success']:
                    laws = analysis['laws_analysis']
                    fitness = laws['law_6_system_fitness']['system_fitness']
                    cascade_nodes = len(laws['law_11_stress_cascade']['cascade_vulnerable_nodes'])
                    metastable = laws['law_12_metastability']['system_metastable']
                    
                    health_data.append({
                        'Country': country,
                        'Fitness': fitness,
                        'Status': 'Critical' if fitness < 5 else 'Warning' if fitness < 15 else 'Stable'
                    })
                    
                    # Generate alerts
                    if fitness < 5:
                        risk_alerts.append(f"üî¥ CRITICAL: {country} fitness at {fitness:.2f}")
                    elif cascade_nodes > 4:
                        risk_alerts.append(f"‚ö†Ô∏è WARNING: {country} has {cascade_nodes} cascade-vulnerable nodes")
                    elif metastable:
                        risk_alerts.append(f"üü° WATCH: {country} showing metastability")
                        
            except Exception:
                continue
        
        if health_data:
            # Create monitoring dashboard
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # Health status chart
                import plotly.express as px
                health_df = pd.DataFrame(health_data)
                
                fig = px.bar(health_df, x='Country', y='Fitness', 
                           color='Status',
                           color_discrete_map={
                               'Critical': 'red',
                               'Warning': 'orange', 
                               'Stable': 'green'
                           },
                           title='Real-time System Health Monitor')
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Alert panel
                st.markdown("**üö® Active Alerts**")
                if risk_alerts:
                    for alert in risk_alerts[:10]:  # Show top 10
                        st.warning(alert)
                else:
                    st.success("All systems stable")
                
                # Summary metrics
                total_critical = sum(1 for h in health_data if h['Status'] == 'Critical')
                total_warning = sum(1 for h in health_data if h['Status'] == 'Warning')
                total_stable = sum(1 for h in health_data if h['Status'] == 'Stable')
                
                st.metric("Critical Systems", total_critical)
                st.metric("Warning Systems", total_warning)
                st.metric("Stable Systems", total_stable)

def create_prediction_laboratory(datasets: Dict, selected_country: str):
    """Prediction laboratory interface"""
    st.markdown('<div class="sub-header">üîÆ Prediction Laboratory</div>', unsafe_allow_html=True)
    
    if selected_country and selected_country in datasets:
        st.markdown(f"**Prediction Analysis: {selected_country}**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Scenario Parameters**")
            
            prediction_years = st.slider("Prediction Horizon (years)", 5, 50, 20)
            shock_intensity = st.slider("External Shock Intensity", 0.0, 3.0, 1.0)
            intervention_type = st.selectbox(
                "Intervention Type:",
                ["None", "Elite Circulation", "Capacity Building", "Stress Reduction"]
            )
            
        with col2:
            st.markdown("**Prediction Method**")
            method = st.selectbox(
                "Method:",
                ["Theoretical Simulation", "Trend Extrapolation", "Machine Learning"]
            )
            
            confidence_level = st.selectbox("Confidence Level:", ["90%", "95%", "99%"])
        
        if st.button("Generate Predictions"):
            st.info(f"Running {method} prediction for {prediction_years} years...")
            
            try:
                df = datasets[selected_country]['data']
                analysis = analyze_dataset_with_laws(df, selected_country)
                
                if analysis['success'] and method == "Theoretical Simulation":
                    from advanced_cams_laws import CAMSNodeSimulator
                    
                    # Use current state as initial condition
                    initial_nodes = analysis['raw_nodes']
                    
                    # Add intervention effects
                    if intervention_type == "Elite Circulation":
                        initial_nodes[[0, 1, 3], 0] += 1.0  # Boost elite coherence
                    elif intervention_type == "Capacity Building":
                        initial_nodes[:, 1] += 0.5  # Boost all capacities
                    elif intervention_type == "Stress Reduction":
                        initial_nodes[:, 2] *= 0.8  # Reduce stress
                    
                    # Create external shocks
                    shock_timeline = {}
                    if shock_intensity > 0:
                        shock_timeline[prediction_years * 0.3] = {
                            'Executive': [0, 0, shock_intensity, 0],
                            'Property_Owners': [-shock_intensity*0.5, -shock_intensity*0.3, shock_intensity, 0]
                        }
                    
                    # Run simulation
                    simulator = CAMSNodeSimulator(initial_nodes)
                    times, trajectories = simulator.simulate(
                        time_span=(0, prediction_years),
                        dt=0.5,
                        external_shocks_timeline=shock_timeline
                    )
                    
                    # Analyze final state
                    final_analysis = simulator.analyze_laws_compliance(trajectories[-1])
                    final_fitness = final_analysis['law_6_system_fitness']['system_fitness']
                    final_transform = final_analysis['law_13_transformation']['transformation_score']
                    
                    # Display predictions
                    col_a, col_b, col_c = st.columns(3)
                    
                    with col_a:
                        current_fitness = analysis['laws_analysis']['law_6_system_fitness']['system_fitness']
                        change = final_fitness - current_fitness
                        st.metric("Predicted Fitness", f"{final_fitness:.2f}", 
                                delta=f"{change:+.2f}")
                    
                    with col_b:
                        transform_status = "Likely" if final_transform > 0.6 else "Unlikely"
                        st.metric("Transformation", transform_status)
                    
                    with col_c:
                        survival_prob = min(final_fitness / 20.0, 1.0) * 100
                        st.metric("Survival Probability", f"{survival_prob:.1f}%")
                    
                    # Plot prediction trajectory
                    import plotly.graph_objects as go
                    
                    # Calculate system health over time
                    health_timeline = []
                    for i in range(len(times)):
                        try:
                            temp_analysis = simulator.analyze_laws_compliance(trajectories[i])
                            fitness = temp_analysis['law_6_system_fitness']['system_fitness']
                            health_timeline.append(fitness)
                        except:
                            health_timeline.append(0)
                    
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=times,
                        y=health_timeline,
                        mode='lines',
                        name='Predicted Health',
                        line=dict(color='blue')
                    ))
                    
                    if shock_intensity > 0:
                        fig.add_vline(x=prediction_years * 0.3, 
                                    line_dash="dash", 
                                    annotation_text="External Shock")
                    
                    fig.update_layout(
                        title=f'{selected_country} - {prediction_years} Year Prediction',
                        xaxis_title='Years',
                        yaxis_title='System Fitness'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
            except Exception as e:
                st.error(f"Prediction failed: {e}")

def create_system_diagnostics_interface(datasets: Dict):
    """System diagnostics interface"""
    st.markdown('<div class="sub-header">üõ†Ô∏è System Diagnostics</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Data Quality Assessment**")
        
        if st.button("Run Data Quality Check"):
            quality_report = []
            
            for country, data in datasets.items():
                try:
                    df = data['data']
                    
                    # Check for missing values
                    missing_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
                    
                    # Check for duplicates
                    duplicates = df.duplicated().sum()
                    
                    # Check data ranges
                    numeric_cols = df.select_dtypes(include=[np.number]).columns
                    outliers = 0
                    for col in numeric_cols:
                        Q1 = df[col].quantile(0.25)
                        Q3 = df[col].quantile(0.75)
                        IQR = Q3 - Q1
                        outliers += ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()
                    
                    quality_score = max(0, 100 - missing_pct - (duplicates/len(df)*10) - (outliers/len(df)*5))
                    
                    quality_report.append({
                        'Dataset': country,
                        'Quality Score': f"{quality_score:.1f}%",
                        'Missing Data': f"{missing_pct:.1f}%",
                        'Duplicates': duplicates,
                        'Outliers': outliers,
                        'Status': 'Good' if quality_score > 80 else 'Fair' if quality_score > 60 else 'Poor'
                    })
                    
                except Exception as e:
                    quality_report.append({
                        'Dataset': country,
                        'Quality Score': 'Error',
                        'Missing Data': 'N/A',
                        'Duplicates': 'N/A',
                        'Outliers': 'N/A',
                        'Status': 'Error'
                    })
            
            quality_df = pd.DataFrame(quality_report)
            st.dataframe(quality_df, use_container_width=True)
    
    with col2:
        st.markdown("**System Performance**")
        
        if st.button("Performance Benchmark"):
            st.info("Running performance tests...")
            
            import time
            
            # Test analysis speed
            test_times = []
            for i, (country, data) in enumerate(list(datasets.items())[:5]):
                start_time = time.time()
                try:
                    df = data['data']
                    analysis = analyze_dataset_with_laws(df, country)
                    end_time = time.time()
                    test_times.append(end_time - start_time)
                except:
                    test_times.append(float('inf'))
            
            avg_time = np.mean([t for t in test_times if t != float('inf')])
            
            st.metric("Average Analysis Time", f"{avg_time:.2f}s")
            st.metric("Datasets Processed", len([t for t in test_times if t != float('inf')]))
            st.metric("Success Rate", f"{len([t for t in test_times if t != float('inf')])/len(test_times)*100:.1f}%")
            
            # Memory usage estimate
            total_records = sum(data['records'] for data in datasets.values())
            memory_est = total_records * 0.001  # Rough estimate in MB
            st.metric("Est. Memory Usage", f"{memory_est:.1f} MB")
        
        st.markdown("**Framework Status**")
        
        # Component status check
        components = {
            "CAMS Analyzer": True,
            "13 Universal Laws": True,
            "Visualizations": True,
            "Data Import": True,
            "Export Functions": True
        }
        
        for component, status in components.items():
            if status:
                st.success(f"‚úÖ {component}: Operational")
            else:
                st.error(f"‚ùå {component}: Error")

def main():
    """Main application function"""
    
    # Header
    st.markdown("""
    <div style="text-align: center; padding: 2rem 0;">
        <h1>üåç Advanced CAMS Framework Interface</h1>
        <h3>Complex Adaptive Model State Analysis with 13 Universal Laws</h3>
        <p><em>Comprehensive Civilization Analysis ‚Ä¢ Real Data Integration ‚Ä¢ Theoretical Modeling</em></p>
    </div>
    """, unsafe_allow_html=True)
    
    # Load available datasets
    with st.spinner("Loading available datasets..."):
        datasets = load_available_datasets()
    
    if not datasets:
        st.error("No datasets found! Please ensure CSV files are in the current directory.")
        st.stop()
    
    # Display dataset statistics
    st.markdown("### üìä Available Datasets Overview")
    
    # Create summary statistics
    total_datasets = len(datasets)
    working_datasets = len([d for d in datasets.values() if d.get('data') is not None])
    error_datasets = total_datasets - working_datasets
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Datasets", total_datasets)
    with col2:
        st.metric("Working Datasets", working_datasets)
    with col3:
        st.metric("Error Datasets", error_datasets)
    with col4:
        total_records = sum(d.get('records', 0) for d in datasets.values())
        st.metric("Total Records", f"{total_records:,}")
    
    # Show dataset types
    node_based = len([d for d in datasets.values() if d.get('type') == 'Node-based'])
    traditional = len([d for d in datasets.values() if d.get('type') == 'Traditional'])
    
    st.write(f"**Dataset Types:** {traditional} Traditional, {node_based} Node-based")
    
    # Dataset browser
    with st.expander("üìã Browse All Available Datasets"):
        # Create a DataFrame for better display
        dataset_info = []
        for name, info in datasets.items():
            dataset_info.append({
                'Country': name,
                'Type': info.get('type', 'Unknown'),
                'Records': info.get('records', 0),
                'Years': info.get('years', 'Unknown'),
                'Columns': info.get('columns', 0),
                'File': info.get('filename', 'Unknown')
            })
        
        dataset_df = pd.DataFrame(dataset_info)
        dataset_df = dataset_df.sort_values('Records', ascending=False)
        
        st.dataframe(
            dataset_df,
            column_config={
                "Country": st.column_config.TextColumn("Country", width="medium"),
                "Type": st.column_config.SelectboxColumn("Type", options=["Traditional", "Node-based", "Error"]),
                "Records": st.column_config.NumberColumn("Records", format="%d"),
                "Years": st.column_config.TextColumn("Time Period"),
                "Columns": st.column_config.NumberColumn("Columns"),
                "File": st.column_config.TextColumn("Filename", width="small")
            },
            hide_index=True,
            use_container_width=True
        )
    
    # Sidebar configuration
    st.sidebar.header("üéõÔ∏è Analysis Configuration")
    
    # Dataset selection
    selected_country = st.sidebar.selectbox(
        "Select Civilization for Analysis:",
        options=list(datasets.keys()),
        help="Choose a civilization dataset for detailed analysis"
    )
    
    # Analysis mode selection
    analysis_mode = st.sidebar.selectbox(
        "Analysis Mode:",
        [
            "Single Civilization",
            "Comparative Analysis", 
            "Theoretical Simulation",
            "üî¨ Advanced Analytics Suite",
            "üìä Data Export & Reports",
            "üéØ Custom Law Testing",
            "üåê Network Analysis Tools",
            "‚ö° Real-time Monitoring",
            "üîÆ Prediction Laboratory",
            "üõ†Ô∏è System Diagnostics"
        ],
        help="Choose the type of analysis to perform"
    )
    
    # Display dataset info
    if selected_country:
        country_data = datasets[selected_country]
        st.sidebar.markdown(f"""
        **Dataset Information:**
        - **File:** {country_data['filename']}
        - **Records:** {country_data['records']:,}
        - **Time Span:** {country_data['years']}
        """)
    
    # Main content area
    if analysis_mode == "Single Civilization":
        if selected_country:
            country_data = datasets[selected_country]
            
            # Analyze the selected dataset
            with st.spinner(f"Analyzing {selected_country}..."):
                analysis_results = analyze_dataset_with_laws(
                    country_data['data'], 
                    selected_country
                )
            
            # Display results
            display_civilization_overview(country_data, analysis_results)
            
            if analysis_results['success']:
                # Create tabs for different analysis views
                tab1, tab2, tab3 = st.tabs(["üìä Universal Laws", "‚ö†Ô∏è Risk Assessment", "üìà Visualizations"])
                
                with tab1:
                    display_thirteen_laws_analysis(analysis_results['laws_analysis'])
                
                with tab2:
                    display_risk_assessment(analysis_results)
                
                with tab3:
                    # Traditional CAMS visualizations
                    st.markdown("**Traditional CAMS Visualizations**")
                    
                    try:
                        visualizer = CAMSVisualizer()
                        df = country_data['data']
                        
                        # System health timeline
                        fig_timeline = visualizer.plot_system_health_timeline(df)
                        st.plotly_chart(fig_timeline, use_container_width=True)
                        
                        # Four dimensions radar
                        analyzer = CAMSAnalyzer()
                        year_col = analyzer._get_column_name(df, 'year')
                        latest_year = df[year_col].max()
                        
                        fig_radar = visualizer.plot_four_dimensions_radar(df, latest_year)
                        st.plotly_chart(fig_radar, use_container_width=True)
                        
                    except Exception as e:
                        st.error(f"Visualization error: {e}")
    
    elif analysis_mode == "Comparative Analysis":
        display_comparative_analysis(datasets)
    
    elif analysis_mode == "Theoretical Simulation":
        create_theoretical_simulation_interface()
    
    elif analysis_mode == "üî¨ Advanced Analytics Suite":
        create_advanced_analytics_suite(datasets, selected_country)
    
    elif analysis_mode == "üìä Data Export & Reports":
        create_data_export_interface(datasets, selected_country)
    
    elif analysis_mode == "üéØ Custom Law Testing":
        create_custom_law_testing_interface(datasets, selected_country)
    
    elif analysis_mode == "üåê Network Analysis Tools":
        create_network_analysis_interface(datasets, selected_country)
    
    elif analysis_mode == "‚ö° Real-time Monitoring":
        create_realtime_monitoring_interface(datasets)
    
    elif analysis_mode == "üîÆ Prediction Laboratory":
        create_prediction_laboratory(datasets, selected_country)
    
    elif analysis_mode == "üõ†Ô∏è System Diagnostics":
        create_system_diagnostics_interface(datasets)
    
    # Footer information
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    **üî¨ Framework Status:**
    - ‚úÖ 13 Universal Laws Implemented
    - ‚úÖ Real Data Integration Active  
    - ‚úÖ Theoretical Modeling Ready
    - ‚úÖ 30+ Datasets Available
    
    **üìä Analysis Capabilities:**
    - System Health Assessment
    - Risk Factor Identification  
    - Transformation Prediction
    - Comparative Studies
    - Theoretical Simulation
    """)

if __name__ == "__main__":
    main()